{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "2Bl6_SQLvaN_"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Wed Mar  1 09:05:03 2023 - 2024/06/27\n",
        "\n",
        "@author: AnahÃ­ Romo\n",
        "\"\"\"\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputRegressor.html\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html\n",
        "\n",
        "# example of making a prediction with the direct multioutput regression model\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOiBBllGvhbE",
        "outputId": "9d8b878b-d07c-42e6-b7fb-39d747502e8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1000, 10)\n",
            "Primera muestra de X: [ 0.72667997  0.98199366 -0.37195994  0.22445073  0.74205658 -1.09330391\n",
            " -1.40525766  0.438562    0.92781985  1.96427946]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import make_regression\n",
        "\n",
        "# ðŸ“Œ 1. Generamos un dataset de regresiÃ³n artificial\n",
        "X, y = make_regression(\n",
        "    n_samples=1000,      # nÃºmero de muestras = 1000 filas (observaciones)\n",
        "    n_features=10,       # cada muestra tiene 10 caracterÃ­sticas (columnas)\n",
        "    n_informative=2,     # solo 2 de esas 10 caracterÃ­sticas realmente influyen en la salida\n",
        "    n_targets=2,         # queremos predecir 2 variables de salida al mismo tiempo (multi-output regression)\n",
        "    random_state=1,      # semilla para reproducibilidad\n",
        "    noise=0.5            # ruido gaussiano agregado a la salida para simular datos mÃ¡s realistas\n",
        ")\n",
        "\n",
        "# ðŸ“Œ 2. Revisamos la forma de la matriz de entrada\n",
        "print(X.shape)  # (1000, 10) â†’ 1000 filas x 10 features\n",
        "\n",
        "# ðŸ“Œ 3. Vemos la primera fila de X\n",
        "# Esto es un vector de 10 nÃºmeros que representa las 10 caracterÃ­sticas de un ejemplo\n",
        "print(\"Primera muestra de X:\", X[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zY2AM49xEn7",
        "outputId": "ef2d1ecd-1465-48c8-9ecc-742330b93a81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1000, 2)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([-53.3740129 ,  15.62916171])"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(y.shape)\n",
        "y[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uXcpLgl4T9g",
        "outputId": "5bfd5e5c-5794-4411-ee90-631b101b6fbf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10']"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "names=[f'x{i+1}' for i in range(10)]\n",
        "names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "kpJcggX24qNs",
        "outputId": "b109cc5c-626d-4cad-9868-60b38a521aa6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>x3</th>\n",
              "      <th>x4</th>\n",
              "      <th>x5</th>\n",
              "      <th>x6</th>\n",
              "      <th>x7</th>\n",
              "      <th>x8</th>\n",
              "      <th>x9</th>\n",
              "      <th>x10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.726680</td>\n",
              "      <td>0.981994</td>\n",
              "      <td>-0.371960</td>\n",
              "      <td>0.224451</td>\n",
              "      <td>0.742057</td>\n",
              "      <td>-1.093304</td>\n",
              "      <td>-1.405258</td>\n",
              "      <td>0.438562</td>\n",
              "      <td>0.927820</td>\n",
              "      <td>1.964279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.489084</td>\n",
              "      <td>-0.090965</td>\n",
              "      <td>0.578705</td>\n",
              "      <td>0.990631</td>\n",
              "      <td>-0.550144</td>\n",
              "      <td>-1.468319</td>\n",
              "      <td>0.311875</td>\n",
              "      <td>-1.902717</td>\n",
              "      <td>0.600032</td>\n",
              "      <td>-1.010139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.175245</td>\n",
              "      <td>1.558688</td>\n",
              "      <td>1.119899</td>\n",
              "      <td>0.861289</td>\n",
              "      <td>0.483884</td>\n",
              "      <td>-1.987830</td>\n",
              "      <td>-2.048200</td>\n",
              "      <td>2.369730</td>\n",
              "      <td>1.562420</td>\n",
              "      <td>-0.870802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.443988</td>\n",
              "      <td>0.351517</td>\n",
              "      <td>0.305031</td>\n",
              "      <td>0.202462</td>\n",
              "      <td>0.623651</td>\n",
              "      <td>-2.087238</td>\n",
              "      <td>-0.214191</td>\n",
              "      <td>-0.293695</td>\n",
              "      <td>1.336392</td>\n",
              "      <td>-0.008131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.202059</td>\n",
              "      <td>-0.594676</td>\n",
              "      <td>-1.271874</td>\n",
              "      <td>-0.091764</td>\n",
              "      <td>-0.013095</td>\n",
              "      <td>1.040153</td>\n",
              "      <td>1.083952</td>\n",
              "      <td>-1.251391</td>\n",
              "      <td>-0.769384</td>\n",
              "      <td>-0.254311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>0.283732</td>\n",
              "      <td>0.450391</td>\n",
              "      <td>2.365601</td>\n",
              "      <td>-1.582294</td>\n",
              "      <td>-0.159635</td>\n",
              "      <td>0.982684</td>\n",
              "      <td>-0.006196</td>\n",
              "      <td>-0.120499</td>\n",
              "      <td>0.385565</td>\n",
              "      <td>0.456093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>1.923815</td>\n",
              "      <td>0.612233</td>\n",
              "      <td>-0.605981</td>\n",
              "      <td>-0.452525</td>\n",
              "      <td>0.204377</td>\n",
              "      <td>1.803589</td>\n",
              "      <td>-0.446699</td>\n",
              "      <td>0.744885</td>\n",
              "      <td>-0.036281</td>\n",
              "      <td>-0.832395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>0.241136</td>\n",
              "      <td>-0.320525</td>\n",
              "      <td>-0.277095</td>\n",
              "      <td>0.155405</td>\n",
              "      <td>0.600008</td>\n",
              "      <td>0.095703</td>\n",
              "      <td>0.247136</td>\n",
              "      <td>1.702785</td>\n",
              "      <td>1.186874</td>\n",
              "      <td>0.908461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>-0.169968</td>\n",
              "      <td>1.096016</td>\n",
              "      <td>0.769551</td>\n",
              "      <td>-0.715846</td>\n",
              "      <td>0.943203</td>\n",
              "      <td>-0.988518</td>\n",
              "      <td>-1.268590</td>\n",
              "      <td>-0.296347</td>\n",
              "      <td>0.228370</td>\n",
              "      <td>-0.045193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>-1.182318</td>\n",
              "      <td>0.661020</td>\n",
              "      <td>-0.665755</td>\n",
              "      <td>0.825030</td>\n",
              "      <td>0.201830</td>\n",
              "      <td>-1.674196</td>\n",
              "      <td>0.242669</td>\n",
              "      <td>1.792158</td>\n",
              "      <td>-0.120465</td>\n",
              "      <td>-1.233121</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows Ã— 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           x1        x2        x3        x4        x5        x6        x7  \\\n",
              "0    0.726680  0.981994 -0.371960  0.224451  0.742057 -1.093304 -1.405258   \n",
              "1   -0.489084 -0.090965  0.578705  0.990631 -0.550144 -1.468319  0.311875   \n",
              "2    1.175245  1.558688  1.119899  0.861289  0.483884 -1.987830 -2.048200   \n",
              "3   -0.443988  0.351517  0.305031  0.202462  0.623651 -2.087238 -0.214191   \n",
              "4    1.202059 -0.594676 -1.271874 -0.091764 -0.013095  1.040153  1.083952   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "995  0.283732  0.450391  2.365601 -1.582294 -0.159635  0.982684 -0.006196   \n",
              "996  1.923815  0.612233 -0.605981 -0.452525  0.204377  1.803589 -0.446699   \n",
              "997  0.241136 -0.320525 -0.277095  0.155405  0.600008  0.095703  0.247136   \n",
              "998 -0.169968  1.096016  0.769551 -0.715846  0.943203 -0.988518 -1.268590   \n",
              "999 -1.182318  0.661020 -0.665755  0.825030  0.201830 -1.674196  0.242669   \n",
              "\n",
              "           x8        x9       x10  \n",
              "0    0.438562  0.927820  1.964279  \n",
              "1   -1.902717  0.600032 -1.010139  \n",
              "2    2.369730  1.562420 -0.870802  \n",
              "3   -0.293695  1.336392 -0.008131  \n",
              "4   -1.251391 -0.769384 -0.254311  \n",
              "..        ...       ...       ...  \n",
              "995 -0.120499  0.385565  0.456093  \n",
              "996  0.744885 -0.036281 -0.832395  \n",
              "997  1.702785  1.186874  0.908461  \n",
              "998 -0.296347  0.228370 -0.045193  \n",
              "999  1.792158 -0.120465 -1.233121  \n",
              "\n",
              "[1000 rows x 10 columns]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "XX=pd.DataFrame(X, columns=names)\n",
        "XX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGPAD3wfxSu0",
        "outputId": "b745f7b8-6a54-48cf-8f3f-549654351eda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Forma de Xp: (1000, 66)\n",
            "Segunda fila de Xp (66 features):\n",
            " [ 1.         -0.48908438 -0.09096474  0.57870467  0.99063126 -0.55014423\n",
            " -1.46831866  0.3118749  -1.9027168   0.60003224 -1.01013865  0.23920353\n",
            "  0.04448943 -0.28303541 -0.48450227  0.26906695  0.71813172 -0.15253314\n",
            "  0.93058906 -0.29346639  0.49404303  0.00827458 -0.05264172 -0.09011251\n",
            "  0.05004372  0.13356522 -0.02836962  0.17308013 -0.05458177  0.091887\n",
            "  0.3348991   0.57328294 -0.31837104 -0.84972287  0.18048346 -1.10111111\n",
            "  0.34724146 -0.58457195  0.98135029 -0.54499007 -1.45456236  0.30895302\n",
            " -1.88489074  0.59441069 -1.00067492  0.30265867  0.80778704 -0.17157617\n",
            "  1.04676867 -0.33010427  0.55572195  2.15595969 -0.45793173  2.79379458\n",
            " -0.88103853  1.48320542  0.09726595 -0.59340961  0.18713499 -0.31503689\n",
            "  3.62033123 -1.14169142  1.92200777  0.36003869 -0.60611575  1.02038008]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "# ðŸ“Œ PolynomialFeatures Â¿Para quÃ© sirve?\n",
        "\n",
        "# Le das a un modelo lineal la capacidad de aprender curvas y relaciones mÃ¡s complejas.\n",
        "# En lugar de entrenar redes neuronales o modelos no lineales pesados, podÃ©s usar esta tÃ©cnica en problemas mÃ¡s simples.\n",
        "# Muy usado en Polynomial Regression o Modelos Lineales Generalizados.\n",
        "\n",
        "# ðŸ“Œ Recordemos:\n",
        "# X tiene 1000 muestras y 10 variables (shape = (1000, 10))\n",
        "\n",
        "# ðŸ“Œ 1. Creamos el generador de caracterÃ­sticas polinÃ³micas de grado 2\n",
        "# - degree=2 â†’ genera tÃ©rminos hasta grado 2 (cuadrÃ¡ticos)\n",
        "# - include_bias=True â†’ incluye el tÃ©rmino constante (1)\n",
        "poly = PolynomialFeatures(degree=2, include_bias=True)\n",
        "\n",
        "# ðŸ“Œ 2. Transformamos X en su versiÃ³n polinÃ³mica\n",
        "# fit_transform genera todas las combinaciones de features hasta el grado indicado\n",
        "Xp = poly.fit_transform(X)\n",
        "\n",
        "# ðŸ“Œ 3. Revisamos la forma del nuevo array\n",
        "print(\"Forma de Xp:\", Xp.shape)  \n",
        "# DeberÃ­a ser (1000, 66) â†’ 1000 filas y 66 columnas (features polinÃ³micas)\n",
        "\n",
        "# ðŸ“Œ 4. Vemos la segunda fila (Ã­ndice 1) con todas sus features polinÃ³micas\n",
        "print(\"Segunda fila de Xp (66 features):\\n\", Xp[1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJEH3Mjf6YP-",
        "outputId": "570dee99-085e-481e-c638-40ab4a96d62a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['1', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10',\n",
              "       'x1^2', 'x1 x2', 'x1 x3', 'x1 x4', 'x1 x5', 'x1 x6', 'x1 x7',\n",
              "       'x1 x8', 'x1 x9', 'x1 x10', 'x2^2', 'x2 x3', 'x2 x4', 'x2 x5',\n",
              "       'x2 x6', 'x2 x7', 'x2 x8', 'x2 x9', 'x2 x10', 'x3^2', 'x3 x4',\n",
              "       'x3 x5', 'x3 x6', 'x3 x7', 'x3 x8', 'x3 x9', 'x3 x10', 'x4^2',\n",
              "       'x4 x5', 'x4 x6', 'x4 x7', 'x4 x8', 'x4 x9', 'x4 x10', 'x5^2',\n",
              "       'x5 x6', 'x5 x7', 'x5 x8', 'x5 x9', 'x5 x10', 'x6^2', 'x6 x7',\n",
              "       'x6 x8', 'x6 x9', 'x6 x10', 'x7^2', 'x7 x8', 'x7 x9', 'x7 x10',\n",
              "       'x8^2', 'x8 x9', 'x8 x10', 'x9^2', 'x9 x10', 'x10^2'], dtype=object)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "names2=poly.get_feature_names_out(names)\n",
        "names2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "9rIDaMgHvvp3",
        "outputId": "392920b6-dc32-48d4-c931-1a16d4e95c6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo entrenado sobre features polinÃ³micas para 2 targets.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "\n",
        "# ðŸ“Œ 1. Definimos el modelo base\n",
        "# LinearRegression â†’ un modelo lineal simple\n",
        "# fit_intercept=False â†’ como ya agregamos el tÃ©rmino constante en PolynomialFeatures,\n",
        "# no queremos que la regresiÃ³n aÃ±ada otro intercepto.\n",
        "model = LinearRegression(fit_intercept=False)\n",
        "\n",
        "# ðŸ“Œ 2. Creamos un \"wrapper\" de salida mÃºltiple\n",
        "# MultiOutputRegressor permite entrenar un modelo que prediga mÃ¡s de una variable target a la vez.\n",
        "# En tu caso, y tiene 2 columnas (n_targets=2).\n",
        "wrapper = MultiOutputRegressor(model)\n",
        "\n",
        "# ðŸ“Œ 3. Entrenamos el modelo sobre TODO el dataset\n",
        "# Xp = features polinÃ³micas (66 columnas generadas con PolynomialFeatures)\n",
        "# y  = variables de salida (2 columnas)\n",
        "wrapper.fit(Xp, y)\n",
        "\n",
        "print(\"Modelo entrenado sobre features polinÃ³micas para 2 targets.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "Qa2_Pe7W8x7K",
        "outputId": "ef34b582-2b0c-46d0-99c8-b9f4199462fa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>x3</th>\n",
              "      <th>x4</th>\n",
              "      <th>x5</th>\n",
              "      <th>x6</th>\n",
              "      <th>x7</th>\n",
              "      <th>x8</th>\n",
              "      <th>x9</th>\n",
              "      <th>...</th>\n",
              "      <th>x7^2</th>\n",
              "      <th>x7 x8</th>\n",
              "      <th>x7 x9</th>\n",
              "      <th>x7 x10</th>\n",
              "      <th>x8^2</th>\n",
              "      <th>x8 x9</th>\n",
              "      <th>x8 x10</th>\n",
              "      <th>x9^2</th>\n",
              "      <th>x9 x10</th>\n",
              "      <th>x10^2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.726680</td>\n",
              "      <td>0.981994</td>\n",
              "      <td>-0.371960</td>\n",
              "      <td>0.224451</td>\n",
              "      <td>0.742057</td>\n",
              "      <td>-1.093304</td>\n",
              "      <td>-1.405258</td>\n",
              "      <td>0.438562</td>\n",
              "      <td>0.927820</td>\n",
              "      <td>...</td>\n",
              "      <td>1.974749</td>\n",
              "      <td>-0.616293</td>\n",
              "      <td>-1.303826</td>\n",
              "      <td>-2.760319</td>\n",
              "      <td>0.192337</td>\n",
              "      <td>0.406907</td>\n",
              "      <td>0.861458</td>\n",
              "      <td>0.860850</td>\n",
              "      <td>1.822497</td>\n",
              "      <td>3.858394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.489084</td>\n",
              "      <td>-0.090965</td>\n",
              "      <td>0.578705</td>\n",
              "      <td>0.990631</td>\n",
              "      <td>-0.550144</td>\n",
              "      <td>-1.468319</td>\n",
              "      <td>0.311875</td>\n",
              "      <td>-1.902717</td>\n",
              "      <td>0.600032</td>\n",
              "      <td>...</td>\n",
              "      <td>0.097266</td>\n",
              "      <td>-0.593410</td>\n",
              "      <td>0.187135</td>\n",
              "      <td>-0.315037</td>\n",
              "      <td>3.620331</td>\n",
              "      <td>-1.141691</td>\n",
              "      <td>1.922008</td>\n",
              "      <td>0.360039</td>\n",
              "      <td>-0.606116</td>\n",
              "      <td>1.020380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.175245</td>\n",
              "      <td>1.558688</td>\n",
              "      <td>1.119899</td>\n",
              "      <td>0.861289</td>\n",
              "      <td>0.483884</td>\n",
              "      <td>-1.987830</td>\n",
              "      <td>-2.048200</td>\n",
              "      <td>2.369730</td>\n",
              "      <td>1.562420</td>\n",
              "      <td>...</td>\n",
              "      <td>4.195125</td>\n",
              "      <td>-4.853682</td>\n",
              "      <td>-3.200148</td>\n",
              "      <td>1.783576</td>\n",
              "      <td>5.615621</td>\n",
              "      <td>3.702513</td>\n",
              "      <td>-2.063565</td>\n",
              "      <td>2.441155</td>\n",
              "      <td>-1.360557</td>\n",
              "      <td>0.758295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.443988</td>\n",
              "      <td>0.351517</td>\n",
              "      <td>0.305031</td>\n",
              "      <td>0.202462</td>\n",
              "      <td>0.623651</td>\n",
              "      <td>-2.087238</td>\n",
              "      <td>-0.214191</td>\n",
              "      <td>-0.293695</td>\n",
              "      <td>1.336392</td>\n",
              "      <td>...</td>\n",
              "      <td>0.045878</td>\n",
              "      <td>0.062907</td>\n",
              "      <td>-0.286243</td>\n",
              "      <td>0.001742</td>\n",
              "      <td>0.086257</td>\n",
              "      <td>-0.392492</td>\n",
              "      <td>0.002388</td>\n",
              "      <td>1.785945</td>\n",
              "      <td>-0.010866</td>\n",
              "      <td>0.000066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.202059</td>\n",
              "      <td>-0.594676</td>\n",
              "      <td>-1.271874</td>\n",
              "      <td>-0.091764</td>\n",
              "      <td>-0.013095</td>\n",
              "      <td>1.040153</td>\n",
              "      <td>1.083952</td>\n",
              "      <td>-1.251391</td>\n",
              "      <td>-0.769384</td>\n",
              "      <td>...</td>\n",
              "      <td>1.174952</td>\n",
              "      <td>-1.356447</td>\n",
              "      <td>-0.833975</td>\n",
              "      <td>-0.275661</td>\n",
              "      <td>1.565979</td>\n",
              "      <td>0.962800</td>\n",
              "      <td>0.318242</td>\n",
              "      <td>0.591951</td>\n",
              "      <td>0.195663</td>\n",
              "      <td>0.064674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.283732</td>\n",
              "      <td>0.450391</td>\n",
              "      <td>2.365601</td>\n",
              "      <td>-1.582294</td>\n",
              "      <td>-0.159635</td>\n",
              "      <td>0.982684</td>\n",
              "      <td>-0.006196</td>\n",
              "      <td>-0.120499</td>\n",
              "      <td>0.385565</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000038</td>\n",
              "      <td>0.000747</td>\n",
              "      <td>-0.002389</td>\n",
              "      <td>-0.002826</td>\n",
              "      <td>0.014520</td>\n",
              "      <td>-0.046460</td>\n",
              "      <td>-0.054959</td>\n",
              "      <td>0.148661</td>\n",
              "      <td>0.175854</td>\n",
              "      <td>0.208021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.923815</td>\n",
              "      <td>0.612233</td>\n",
              "      <td>-0.605981</td>\n",
              "      <td>-0.452525</td>\n",
              "      <td>0.204377</td>\n",
              "      <td>1.803589</td>\n",
              "      <td>-0.446699</td>\n",
              "      <td>0.744885</td>\n",
              "      <td>-0.036281</td>\n",
              "      <td>...</td>\n",
              "      <td>0.199540</td>\n",
              "      <td>-0.332739</td>\n",
              "      <td>0.016207</td>\n",
              "      <td>0.371830</td>\n",
              "      <td>0.554853</td>\n",
              "      <td>-0.027025</td>\n",
              "      <td>-0.620038</td>\n",
              "      <td>0.001316</td>\n",
              "      <td>0.030200</td>\n",
              "      <td>0.692882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.241136</td>\n",
              "      <td>-0.320525</td>\n",
              "      <td>-0.277095</td>\n",
              "      <td>0.155405</td>\n",
              "      <td>0.600008</td>\n",
              "      <td>0.095703</td>\n",
              "      <td>0.247136</td>\n",
              "      <td>1.702785</td>\n",
              "      <td>1.186874</td>\n",
              "      <td>...</td>\n",
              "      <td>0.061076</td>\n",
              "      <td>0.420820</td>\n",
              "      <td>0.293319</td>\n",
              "      <td>0.224514</td>\n",
              "      <td>2.899478</td>\n",
              "      <td>2.020992</td>\n",
              "      <td>1.546915</td>\n",
              "      <td>1.408670</td>\n",
              "      <td>1.078229</td>\n",
              "      <td>0.825302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.169968</td>\n",
              "      <td>1.096016</td>\n",
              "      <td>0.769551</td>\n",
              "      <td>-0.715846</td>\n",
              "      <td>0.943203</td>\n",
              "      <td>-0.988518</td>\n",
              "      <td>-1.268590</td>\n",
              "      <td>-0.296347</td>\n",
              "      <td>0.228370</td>\n",
              "      <td>...</td>\n",
              "      <td>1.609320</td>\n",
              "      <td>0.375943</td>\n",
              "      <td>-0.289708</td>\n",
              "      <td>0.057331</td>\n",
              "      <td>0.087821</td>\n",
              "      <td>-0.067677</td>\n",
              "      <td>0.013393</td>\n",
              "      <td>0.052153</td>\n",
              "      <td>-0.010321</td>\n",
              "      <td>0.002042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.182318</td>\n",
              "      <td>0.661020</td>\n",
              "      <td>-0.665755</td>\n",
              "      <td>0.825030</td>\n",
              "      <td>0.201830</td>\n",
              "      <td>-1.674196</td>\n",
              "      <td>0.242669</td>\n",
              "      <td>1.792158</td>\n",
              "      <td>-0.120465</td>\n",
              "      <td>...</td>\n",
              "      <td>0.058888</td>\n",
              "      <td>0.434902</td>\n",
              "      <td>-0.029233</td>\n",
              "      <td>-0.299241</td>\n",
              "      <td>3.211831</td>\n",
              "      <td>-0.215892</td>\n",
              "      <td>-2.209947</td>\n",
              "      <td>0.014512</td>\n",
              "      <td>0.148547</td>\n",
              "      <td>1.520587</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows Ã— 66 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       1        x1        x2        x3        x4        x5        x6  \\\n",
              "0    1.0  0.726680  0.981994 -0.371960  0.224451  0.742057 -1.093304   \n",
              "1    1.0 -0.489084 -0.090965  0.578705  0.990631 -0.550144 -1.468319   \n",
              "2    1.0  1.175245  1.558688  1.119899  0.861289  0.483884 -1.987830   \n",
              "3    1.0 -0.443988  0.351517  0.305031  0.202462  0.623651 -2.087238   \n",
              "4    1.0  1.202059 -0.594676 -1.271874 -0.091764 -0.013095  1.040153   \n",
              "..   ...       ...       ...       ...       ...       ...       ...   \n",
              "995  1.0  0.283732  0.450391  2.365601 -1.582294 -0.159635  0.982684   \n",
              "996  1.0  1.923815  0.612233 -0.605981 -0.452525  0.204377  1.803589   \n",
              "997  1.0  0.241136 -0.320525 -0.277095  0.155405  0.600008  0.095703   \n",
              "998  1.0 -0.169968  1.096016  0.769551 -0.715846  0.943203 -0.988518   \n",
              "999  1.0 -1.182318  0.661020 -0.665755  0.825030  0.201830 -1.674196   \n",
              "\n",
              "           x7        x8        x9  ...      x7^2     x7 x8     x7 x9  \\\n",
              "0   -1.405258  0.438562  0.927820  ...  1.974749 -0.616293 -1.303826   \n",
              "1    0.311875 -1.902717  0.600032  ...  0.097266 -0.593410  0.187135   \n",
              "2   -2.048200  2.369730  1.562420  ...  4.195125 -4.853682 -3.200148   \n",
              "3   -0.214191 -0.293695  1.336392  ...  0.045878  0.062907 -0.286243   \n",
              "4    1.083952 -1.251391 -0.769384  ...  1.174952 -1.356447 -0.833975   \n",
              "..        ...       ...       ...  ...       ...       ...       ...   \n",
              "995 -0.006196 -0.120499  0.385565  ...  0.000038  0.000747 -0.002389   \n",
              "996 -0.446699  0.744885 -0.036281  ...  0.199540 -0.332739  0.016207   \n",
              "997  0.247136  1.702785  1.186874  ...  0.061076  0.420820  0.293319   \n",
              "998 -1.268590 -0.296347  0.228370  ...  1.609320  0.375943 -0.289708   \n",
              "999  0.242669  1.792158 -0.120465  ...  0.058888  0.434902 -0.029233   \n",
              "\n",
              "       x7 x10      x8^2     x8 x9    x8 x10      x9^2    x9 x10     x10^2  \n",
              "0   -2.760319  0.192337  0.406907  0.861458  0.860850  1.822497  3.858394  \n",
              "1   -0.315037  3.620331 -1.141691  1.922008  0.360039 -0.606116  1.020380  \n",
              "2    1.783576  5.615621  3.702513 -2.063565  2.441155 -1.360557  0.758295  \n",
              "3    0.001742  0.086257 -0.392492  0.002388  1.785945 -0.010866  0.000066  \n",
              "4   -0.275661  1.565979  0.962800  0.318242  0.591951  0.195663  0.064674  \n",
              "..        ...       ...       ...       ...       ...       ...       ...  \n",
              "995 -0.002826  0.014520 -0.046460 -0.054959  0.148661  0.175854  0.208021  \n",
              "996  0.371830  0.554853 -0.027025 -0.620038  0.001316  0.030200  0.692882  \n",
              "997  0.224514  2.899478  2.020992  1.546915  1.408670  1.078229  0.825302  \n",
              "998  0.057331  0.087821 -0.067677  0.013393  0.052153 -0.010321  0.002042  \n",
              "999 -0.299241  3.211831 -0.215892 -2.209947  0.014512  0.148547  1.520587  \n",
              "\n",
              "[1000 rows x 66 columns]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_df=pd.DataFrame(Xp, columns=names2)\n",
        "X_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7_-01ynvwnt",
        "outputId": "67ad079e-4f3b-4dfd-950b-93515bebf0fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape de rowp (fila expandida a polinomios): (1, 66)\n",
            "Predicted: yhat=[-30.11406321  -2.5434302 ]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# ðŸ“Œ 1. Definimos un ejemplo puntual (fila con 10 variables de entrada)\n",
        "# Estas son las 10 features originales (como las que generaste con make_regression)\n",
        "row = [0.21947749, 0.32948997, 0.81560036, 0.440956,\n",
        "       -0.0606303, -0.29257894, -0.2820059, -0.00290545,\n",
        "       0.96402263, 0.04992249]\n",
        "\n",
        "# ðŸ“Œ 2. Transformamos esa fila a features polinÃ³micas\n",
        "# poly.transform â†’ expande la fila en 66 columnas (1, x1, x2, ..., x1Â², x1*x2, ...)\n",
        "# reshape(1, -1) â†’ convertimos la lista en un array de 1 fila y 10 columnas (forma correcta para sklearn)\n",
        "rowp = poly.transform(np.array(row).reshape(1, -1))\n",
        "print(\"Shape de rowp (fila expandida a polinomios):\", rowp.shape)\n",
        "\n",
        "# ðŸ“Œ 3. Usamos el modelo entrenado para predecir las 2 salidas\n",
        "yhat = wrapper.predict(rowp)\n",
        "\n",
        "# ðŸ“Œ 4. Mostramos el resultado\n",
        "# yhat es un array con 2 valores porque entrenamos el modelo con n_targets=2\n",
        "print(f'Predicted: yhat={yhat[0]}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVcmh87sR7r1",
        "outputId": "c99f1674-4c0e-4518-d7f1-b932834c0008"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9998215439244125\n"
          ]
        }
      ],
      "source": [
        "r2=wrapper.score(Xp, y)\n",
        "print(r2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dn6rjMAAv3rU",
        "outputId": "b3fec833-f52c-4090-f033-9827f154d492"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'estimator__copy_X': True, 'estimator__fit_intercept': False, 'estimator__n_jobs': None, 'estimator__positive': False, 'estimator': LinearRegression(fit_intercept=False), 'n_jobs': None}\n",
            "{'copy_X': True, 'fit_intercept': False, 'n_jobs': None, 'positive': False}\n",
            "[LinearRegression(fit_intercept=False), LinearRegression(fit_intercept=False)]\n"
          ]
        }
      ],
      "source": [
        "# Obtener parÃ¡metros generales del wrapper\n",
        "z = wrapper.get_params()\n",
        "print(z)\n",
        "\n",
        "# Obtener parÃ¡metros del modelo base\n",
        "v = model.get_params()\n",
        "print(v)\n",
        "\n",
        "# Ver los modelos internos entrenados (uno por cada salida)\n",
        "print(wrapper.estimators_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qd2vj8y3v9ka",
        "outputId": "bf6d3174-45d3-4ae9-83da-ea58b6a3bd08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[        Coefficients\n",
            "1          -0.039435\n",
            "x1          0.002178\n",
            "x2          0.010606\n",
            "x3         -0.010485\n",
            "x4         -0.019024\n",
            "...              ...\n",
            "x8 x9       0.017510\n",
            "x8 x10      0.054531\n",
            "x9^2       -0.008369\n",
            "x9 x10      0.034686\n",
            "x10^2       0.002210\n",
            "\n",
            "[66 rows x 1 columns],         Coefficients\n",
            "1          -0.014075\n",
            "x1         -0.013917\n",
            "x2          0.006262\n",
            "x3         -0.027721\n",
            "x4          0.017521\n",
            "...              ...\n",
            "x8 x9       0.009130\n",
            "x8 x10     -0.029899\n",
            "x9^2        0.000577\n",
            "x9 x10     -0.018558\n",
            "x10^2      -0.010158\n",
            "\n",
            "[66 rows x 1 columns]]\n"
          ]
        }
      ],
      "source": [
        "# obtain coef from each estimator\n",
        "\n",
        "coeficientes=[]\n",
        "for estimator in wrapper.estimators_:\n",
        "    c=pd.DataFrame(estimator.coef_, index=X_df.columns, columns=['Coefficients'])\n",
        "    coeficientes.append(c)\n",
        "print(coeficientes)\n",
        "\n",
        "# ðŸ“Œ QuÃ© pasa aquÃ­\n",
        "\n",
        "# wrapper.estimators_ â†’ es la lista de modelos entrenados, uno por cada target.\n",
        "\n",
        "# estimator.coef_ â†’ array con los pesos de las features (en tu caso, 66 coeficientes porque PolynomialFeatures(degree=2) generÃ³ 66 columnas).\n",
        "\n",
        "# Vos estÃ¡s poniendo index=X_df.columns, pero X_df solo tiene 10 columnas originales, no las 66.\n",
        "# ðŸ‘‰ Por eso el Ã­ndice no te va a cuadrar con la cantidad de coeficientes.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
